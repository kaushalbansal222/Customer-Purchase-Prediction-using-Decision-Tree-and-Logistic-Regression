# -*- coding: utf-8 -*-
"""Spend_Score_Scikit-Learn

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W8OtuOvW_GCmo6M24AzW1hoDlPf-cOfx
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""### ðŸ”¹ Data Exploration (Pandas + Visualization)

1. Load the dataset and display the first 10 rows.
2. Show summary statistics (mean, median, min, max) of `Age` and `Income`.
3. Count how many customers purchased vs. didnâ€™t purchase.
4. Plot a histogram of `Spend_Score`.
5. Which city has the highest average income?

---

### ðŸ”¹ Data Preprocessing

6. Encode the categorical variable `Gender` into numeric form (Male = 0, Female = 1).
7. One-hot encode the `City` column.
8. Normalize/scale the `Income` column using StandardScaler.
9. Split the dataset into **train (80%) and test (20%)** sets.

---

### ðŸ”¹ Machine Learning (Scikit-learn)

10. Train a **Logistic Regression** model to predict `Purchased` using all features.
11. Evaluate the model with **accuracy score** on the test set.
12. Create a **confusion matrix** for the predictions.
13. Try a **Decision Tree Classifier** and compare accuracy with Logistic Regression.
14. Use **cross-validation** to check model performance.


"""

df=pd.read_csv('/content/GoogleCollab_Scikit_Practice.csv.csv')

"""**Load the dataset and display the first 10 rows**"""

df.head(10)

"""**How Many Samples are there in DataSet?**"""

df.shape

df.columns

"""**Show summary statistics (mean, median, min, max) of Age and Income**"""

df[['Age','Income']].describe()

"""**Count how many customers purchased vs. didnâ€™t purchase**"""

purchased=df[df['Purchased']==1]['Purchased'].count()
not_purchased=df[df['Purchased']==0]['Purchased'].count()
print("Count of Customers who Purchased: ",purchased)
print("Count of Customers who didn't Purchased: ",not_purchased)

"""**Plot a histogram of Spend_Score**

"""

df['Spend_Score'].hist(bins=50,color='Blue',edgecolor='Black')
plt.xlabel('Spend_Score')
plt.ylabel('Count')
plt.title('Histogram of Spend_Score')
plt.show()

"""**Which city has the highest average income?**"""

highest_avg_income=df.groupby('City')['Income'].mean().idxmax()
print("City with Highest Average Income: ",highest_avg_income)

"""**Encode the categorical variable Gender into numeric form (Male = 0, Female = 1)**"""

gender_mapping={'Male':0, "Female":1}
df['Gender']=df['Gender'].map(gender_mapping)
df.head()

"""**One-hot encode the City column**"""

one_hot_encoded=pd.get_dummies(df,columns=['City'],prefix='Color')
one_hot_encoded.head(10)

"""**Normalize/scale the Income column using StandardScaler.**"""

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
df['Income']=scaler.fit_transform(df[['Income']])
df.head(10)

"""**Split the dataset into train (80%) and test (20%) sets**"""

from sklearn.model_selection import train_test_split
# Dropping 'Education' and 'City' before splitting
X=df[['Age','Income','Spend_Score']]
y=df['Purchased']
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.transform(X_test)

"""**Train a Logistic Regression model to predict Purchased using all features:**"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
model=LogisticRegression()
model.fit(X_train,y_train)

y_pred_log=model.predict(X_test)

log_acc=accuracy_score(y_test,y_pred_log)
print("Accuracy Score:",log_acc)
print("Predicted Labels",y_pred_log)

"""**Create a confusion matrix for the predictions**"""

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score,classification_report
confusion=confusion_matrix(y_test,y_pred_log)
acuuracy=accuracy_score(y_test,y_pred_log)
precision=precision_score(y_test,y_pred_log)
recall=recall_score(y_test,y_pred_log)
f1=f1_score(y_test,y_pred_log)
print("Confusion Matrix:\n")
print(confusion)
print("\nAccuracy Score:",acuuracy)
print("Precision Score:",precision)
print("Recall Score:",recall)
print("F1 Score:",f1)

"""**Try a Decision Tree Classifier and compare accuracy with Logistic Regression**"""

from sklearn.tree import DecisionTreeClassifier
dt_model=DecisionTreeClassifier(max_depth=4,random_state=42)
dt_model.fit(X_train,y_train)

y_pred_dt=dt_model.predict(X_test)

dt_acc=accuracy_score(y_test,y_pred_dt)

print("Logistic Accuracy: ",log_acc)
print("Decision Tree Accuracy Score: ",dt_acc)

print("Logistic Regression Reports:\n",classification_report(y_test,y_pred_log))
print("\nConfusion Matrix:\n",confusion_matrix(y_test,y_pred_log))

print("\nDecision Tree Reports:\n",classification_report(y_test,y_pred_dt))
print("\nConfusion Matrix:\n",confusion_matrix(y_test,y_pred_dt))

"""**Visualize the Decision Tree**"""

from sklearn.tree import plot_tree
plt.figure(figsize=(20,10))
plot_tree(dt_model,rounded=True,fontsize=12,filled=True,feature_names=X.columns,class_names=['not_purchased','purchased'])
plt.show()

"""**Use cross-validation to check model performance**"""

from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, X, y, cv=5)
print(scores)
print("Mean Accuracy: ",scores.mean())